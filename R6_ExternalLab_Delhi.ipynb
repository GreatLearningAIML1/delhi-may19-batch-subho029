{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "R6_ExternalLab_Delhi.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 2",
      "language": "python",
      "name": "python2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYk8NG3yOIT9",
        "colab_type": "text"
      },
      "source": [
        "### A MNIST-like fashion product database\n",
        "\n",
        "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tFO6PuxzOIT_",
        "colab_type": "text"
      },
      "source": [
        "### Load tensorflow"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efNjNImfOIUC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.set_random_seed(42)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l9C4aAIGOIUH",
        "colab_type": "code",
        "outputId": "e2bdb054-e262-471a-9ccd-cbff6541c7e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "tf.__version__"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.15.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcoZBStrOIUQ",
        "colab_type": "text"
      },
      "source": [
        "### Collect Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApbkYXyYSDCt",
        "colab_type": "code",
        "outputId": "9bbaf4fa-169c-458a-d024-fe4efd33498e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "!pip install -U tensorflow==2.0 --quiet"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 86.3MB 30kB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8MB 38.0MB/s \n",
            "\u001b[K     |████████████████████████████████| 450kB 55.5MB/s \n",
            "\u001b[K     |████████████████████████████████| 81kB 9.7MB/s \n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement google-auth~=1.4.0, but you'll have google-auth 1.7.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorboard 2.0.1 has requirement grpcio>=1.24.3, but you'll have grpcio 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA1WsFSeOIUS",
        "colab_type": "code",
        "outputId": "7bbd4eee-1c2e-4de9-dc12-c76526e9ec2c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnbx7TyQOIUY",
        "colab_type": "code",
        "outputId": "a52d9000-b8c7-485b-ad88-40b1546fa711",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 8us/step\n",
            "40960/29515 [=========================================] - 0s 7us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 6s 0us/step\n",
            "26435584/26421880 [==============================] - 6s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 2s 0us/step\n",
            "4431872/4422102 [==============================] - 2s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UbiHj5YPOIUc",
        "colab_type": "code",
        "outputId": "75f3b779-635c-40f6-c3dd-266d1c55738c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(testY[0:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[9 2 1 1 6]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRfwmGGsSxUo",
        "colab_type": "code",
        "outputId": "1ee387a8-39ba-4c47-cc50-9bcca609e4b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SectWD1TVL9",
        "colab_type": "code",
        "outputId": "b3ca4dee-ad8d-40d5-bad4-0aea4e36f706",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testX.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X6H8Lt2ZTaNt",
        "colab_type": "code",
        "outputId": "92d40f2a-19a0-41bb-b8d8-001c2cde51c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testY.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3dP-tDqXTeEl",
        "colab_type": "code",
        "outputId": "c1925ad3-7a8d-41d7-b3e1-96f2096ab908",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainY.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-0ae2cvTlcb",
        "colab_type": "code",
        "outputId": "98acb972-a2f5-46e1-da73-f6e98eb7ed80",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testY[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "9"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDAYzkwyOIUj",
        "colab_type": "text"
      },
      "source": [
        "### Convert both training and testing labels into one-hot vectors.\n",
        "\n",
        "**Hint:** check **tf.keras.utils.to_categorical()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBlfYlANOIUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainY = tf.keras.utils.to_categorical(trainY, num_classes=10)\n",
        "testY = tf.keras.utils.to_categorical(testY, num_classes=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8l-QLTYTv4G",
        "colab_type": "code",
        "outputId": "347b449e-6723-4229-c361-fe86ef244936",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "testY[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "RHV3b9mzOIUq",
        "colab_type": "code",
        "outputId": "78bcbb37-53ce-4057-9c64-fe8c5bd36e59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "source": [
        "print(trainY.shape)\n",
        "print('First 5 examples now are: ', trainY[0:5])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000, 10)\n",
            "('First 5 examples now are: ', array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "       [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
            "       [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FwhQ8e7VOIUw",
        "colab_type": "text"
      },
      "source": [
        "### Visualize the data\n",
        "\n",
        "Plot first 10 images in the triaining set and their labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AvDML2OoOIUx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsXNNPKWU_00",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myHTn7YAT9-V",
        "colab_type": "code",
        "outputId": "03043cb0-2e40-48cd-ef31-d6de1325ef45",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.figure()\n",
        "plt.imshow(trainX[0])\n",
        "plt.colorbar()\n",
        "plt.grid(False)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAD8CAYAAAAfZJO2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kg4EsKxYVKNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "trainX = trainX / 255.0\n",
        "testX = testX / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JDzkZhuVMCz",
        "colab_type": "code",
        "outputId": "511a3ef0-58d6-446a-c680-aa0bd85a17e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        }
      },
      "source": [
        "trainY"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 1.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [1., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPdxUof9V_zJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xvi8dB5-aRbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsecDI7oVTm3",
        "colab_type": "code",
        "outputId": "7eb70e88-5242-4ffb-ccc0-ec9b78a6f570",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(10,10))\n",
        "for i in range(10):\n",
        "plt.subplot(5,5,i+1)\n",
        "plt.xticks([])\n",
        "plt.yticks([])\n",
        "plt.grid(False)\n",
        "plt.imshow(trainX[i], cmap=plt.cm.binary)\n",
        "plt.xlabel(class_names[trainY[i]])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndentationError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-36-c69767aa5586>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    plt.subplot(5,5,i+1)\u001b[0m\n\u001b[0m      ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m expected an indented block\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l4TbJGeSOIU4",
        "colab_type": "text"
      },
      "source": [
        "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ac06XZZTOIU6",
        "colab_type": "code",
        "outputId": "b4f6fd32-90b8-4778-f78c-2be4f8780bbd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "trainX.dtype"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "81vQz224ZlW2",
        "colab_type": "code",
        "outputId": "1f07ec6a-e717-452a-d389-a7f91714e845",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W1110 13:00:04.724555 139628989691776 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling __init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y1I98kMpZlJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBX4vG-4Zk8P",
        "colab_type": "code",
        "outputId": "ab1e65fc-5b70-4104-d91b-358a4489b1b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape (Reshape)            (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5seTmwl6Zkjv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3hQpLv3aOIU_",
        "colab_type": "text"
      },
      "source": [
        "### Execute the model using model.fit()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O59C_-IgOIVB",
        "colab_type": "code",
        "outputId": "bc8ae4f1-8218-4009-dec5-a6289b3d947e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3410
        }
      },
      "source": [
        "model.fit(trainX,trainY,\n",
        "validation_data=(testX,testY),\n",
        "epochs=100,\n",
        "batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 3s 46us/sample - loss: 0.8234 - acc: 0.7405 - val_loss: 0.6531 - val_acc: 0.7821\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.5918 - acc: 0.8069 - val_loss: 0.5837 - val_acc: 0.8070\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.5417 - acc: 0.8219 - val_loss: 0.5499 - val_acc: 0.8182\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.5150 - acc: 0.8291 - val_loss: 0.5318 - val_acc: 0.8190\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4973 - acc: 0.8343 - val_loss: 0.5181 - val_acc: 0.8223\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4846 - acc: 0.8372 - val_loss: 0.5077 - val_acc: 0.8283\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4750 - acc: 0.8403 - val_loss: 0.5006 - val_acc: 0.8287\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4674 - acc: 0.8423 - val_loss: 0.5020 - val_acc: 0.8268\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4611 - acc: 0.8440 - val_loss: 0.4892 - val_acc: 0.8310\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4555 - acc: 0.8467 - val_loss: 0.4861 - val_acc: 0.8329\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4508 - acc: 0.8482 - val_loss: 0.4837 - val_acc: 0.8316\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4467 - acc: 0.8498 - val_loss: 0.4796 - val_acc: 0.8335\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4430 - acc: 0.8509 - val_loss: 0.4753 - val_acc: 0.8350\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4398 - acc: 0.8510 - val_loss: 0.4761 - val_acc: 0.8319\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4369 - acc: 0.8522 - val_loss: 0.4701 - val_acc: 0.8371\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4346 - acc: 0.8522 - val_loss: 0.4687 - val_acc: 0.8349\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4322 - acc: 0.8527 - val_loss: 0.4671 - val_acc: 0.8372\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4299 - acc: 0.8546 - val_loss: 0.4648 - val_acc: 0.8376\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4278 - acc: 0.8546 - val_loss: 0.4641 - val_acc: 0.8376\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4258 - acc: 0.8549 - val_loss: 0.4623 - val_acc: 0.8369\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4244 - acc: 0.8557 - val_loss: 0.4613 - val_acc: 0.8396\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4225 - acc: 0.8556 - val_loss: 0.4594 - val_acc: 0.8401\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4209 - acc: 0.8565 - val_loss: 0.4591 - val_acc: 0.8383\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4194 - acc: 0.8567 - val_loss: 0.4612 - val_acc: 0.8396\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4182 - acc: 0.8577 - val_loss: 0.4565 - val_acc: 0.8392\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4169 - acc: 0.8585 - val_loss: 0.4596 - val_acc: 0.8402\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.4158 - acc: 0.8580 - val_loss: 0.4547 - val_acc: 0.8415\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4144 - acc: 0.8587 - val_loss: 0.4530 - val_acc: 0.8427\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4133 - acc: 0.8587 - val_loss: 0.4546 - val_acc: 0.8411\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4124 - acc: 0.8593 - val_loss: 0.4609 - val_acc: 0.8352\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4113 - acc: 0.8595 - val_loss: 0.4515 - val_acc: 0.8413\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4105 - acc: 0.8598 - val_loss: 0.4509 - val_acc: 0.8417\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4093 - acc: 0.8595 - val_loss: 0.4530 - val_acc: 0.8412\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4087 - acc: 0.8608 - val_loss: 0.4507 - val_acc: 0.8408\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4077 - acc: 0.8609 - val_loss: 0.4494 - val_acc: 0.8418\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4071 - acc: 0.8604 - val_loss: 0.4526 - val_acc: 0.8402\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4064 - acc: 0.8616 - val_loss: 0.4567 - val_acc: 0.8372\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4056 - acc: 0.8619 - val_loss: 0.4471 - val_acc: 0.8429\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4049 - acc: 0.8611 - val_loss: 0.4463 - val_acc: 0.8431\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4041 - acc: 0.8614 - val_loss: 0.4486 - val_acc: 0.8419\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4033 - acc: 0.8619 - val_loss: 0.4456 - val_acc: 0.8438\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4028 - acc: 0.8615 - val_loss: 0.4499 - val_acc: 0.8417\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4024 - acc: 0.8621 - val_loss: 0.4462 - val_acc: 0.8416\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4012 - acc: 0.8622 - val_loss: 0.4481 - val_acc: 0.8411\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.4008 - acc: 0.8625 - val_loss: 0.4475 - val_acc: 0.8441\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.4004 - acc: 0.8623 - val_loss: 0.4447 - val_acc: 0.8422\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3999 - acc: 0.8625 - val_loss: 0.4434 - val_acc: 0.8434\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3990 - acc: 0.8632 - val_loss: 0.4440 - val_acc: 0.8441\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3988 - acc: 0.8632 - val_loss: 0.4445 - val_acc: 0.8430\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3981 - acc: 0.8634 - val_loss: 0.4440 - val_acc: 0.8436\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3976 - acc: 0.8637 - val_loss: 0.4425 - val_acc: 0.8444\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3971 - acc: 0.8627 - val_loss: 0.4432 - val_acc: 0.8443\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3963 - acc: 0.8637 - val_loss: 0.4444 - val_acc: 0.8445\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3961 - acc: 0.8637 - val_loss: 0.4426 - val_acc: 0.8432\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.3957 - acc: 0.8640 - val_loss: 0.4421 - val_acc: 0.8445\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.3952 - acc: 0.8643 - val_loss: 0.4432 - val_acc: 0.8447\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3947 - acc: 0.8649 - val_loss: 0.4413 - val_acc: 0.8445\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3942 - acc: 0.8645 - val_loss: 0.4465 - val_acc: 0.8419\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3937 - acc: 0.8649 - val_loss: 0.4436 - val_acc: 0.8457\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3935 - acc: 0.8648 - val_loss: 0.4447 - val_acc: 0.8436\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3930 - acc: 0.8648 - val_loss: 0.4401 - val_acc: 0.8448\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3926 - acc: 0.8655 - val_loss: 0.4420 - val_acc: 0.8457\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3924 - acc: 0.8657 - val_loss: 0.4412 - val_acc: 0.8439\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3920 - acc: 0.8655 - val_loss: 0.4407 - val_acc: 0.8451\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3916 - acc: 0.8652 - val_loss: 0.4422 - val_acc: 0.8444\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3912 - acc: 0.8660 - val_loss: 0.4425 - val_acc: 0.8456\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3911 - acc: 0.8652 - val_loss: 0.4396 - val_acc: 0.8454\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3904 - acc: 0.8654 - val_loss: 0.4408 - val_acc: 0.8462\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3903 - acc: 0.8661 - val_loss: 0.4390 - val_acc: 0.8455\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3897 - acc: 0.8655 - val_loss: 0.4435 - val_acc: 0.8420\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3896 - acc: 0.8666 - val_loss: 0.4386 - val_acc: 0.8451\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3893 - acc: 0.8654 - val_loss: 0.4402 - val_acc: 0.8444\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3888 - acc: 0.8665 - val_loss: 0.4389 - val_acc: 0.8441\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3887 - acc: 0.8659 - val_loss: 0.4377 - val_acc: 0.8443\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3882 - acc: 0.8665 - val_loss: 0.4389 - val_acc: 0.8438\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3880 - acc: 0.8665 - val_loss: 0.4376 - val_acc: 0.8457\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3877 - acc: 0.8666 - val_loss: 0.4386 - val_acc: 0.8442\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3874 - acc: 0.8663 - val_loss: 0.4391 - val_acc: 0.8455\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3871 - acc: 0.8672 - val_loss: 0.4368 - val_acc: 0.8463\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3867 - acc: 0.8667 - val_loss: 0.4420 - val_acc: 0.8430\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3864 - acc: 0.8675 - val_loss: 0.4376 - val_acc: 0.8453\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3862 - acc: 0.8672 - val_loss: 0.4385 - val_acc: 0.8439\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3860 - acc: 0.8670 - val_loss: 0.4400 - val_acc: 0.8447\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3857 - acc: 0.8671 - val_loss: 0.4365 - val_acc: 0.8449\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3855 - acc: 0.8672 - val_loss: 0.4390 - val_acc: 0.8434\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.3852 - acc: 0.8662 - val_loss: 0.4386 - val_acc: 0.8426\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.3849 - acc: 0.8680 - val_loss: 0.4370 - val_acc: 0.8451\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 3s 45us/sample - loss: 0.3846 - acc: 0.8666 - val_loss: 0.4374 - val_acc: 0.8455\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 3s 44us/sample - loss: 0.3846 - acc: 0.8669 - val_loss: 0.4375 - val_acc: 0.8438\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3842 - acc: 0.8678 - val_loss: 0.4373 - val_acc: 0.8451\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3841 - acc: 0.8678 - val_loss: 0.4405 - val_acc: 0.8437\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3834 - acc: 0.8682 - val_loss: 0.4372 - val_acc: 0.8436\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3836 - acc: 0.8672 - val_loss: 0.4373 - val_acc: 0.8449\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3833 - acc: 0.8680 - val_loss: 0.4374 - val_acc: 0.8449\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 2s 41us/sample - loss: 0.3832 - acc: 0.8679 - val_loss: 0.4371 - val_acc: 0.8468\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3829 - acc: 0.8673 - val_loss: 0.4365 - val_acc: 0.8445\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3828 - acc: 0.8678 - val_loss: 0.4377 - val_acc: 0.8439\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3823 - acc: 0.8677 - val_loss: 0.4379 - val_acc: 0.8433\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 3s 43us/sample - loss: 0.3820 - acc: 0.8675 - val_loss: 0.4364 - val_acc: 0.8456\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 3s 42us/sample - loss: 0.3819 - acc: 0.8684 - val_loss: 0.4401 - val_acc: 0.8429\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efdac9ff8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdzDtGwDOIVF",
        "colab_type": "text"
      },
      "source": [
        "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kndfpdidOIVI",
        "colab_type": "code",
        "outputId": "20e55d21-ac67-45b6-f549-e2f64622005a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        }
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_1 (Reshape)          (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 10,986\n",
            "Trainable params: 9,418\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mwk3T5LJOIVN",
        "colab_type": "text"
      },
      "source": [
        "### Execute the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNLR8tcBOIVP",
        "colab_type": "code",
        "outputId": "bfed2a3f-744d-4b7d-de22-ff2a39311aff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3410
        }
      },
      "source": [
        "model.fit(trainX,trainY,\n",
        "validation_data=(testX,testY),\n",
        "epochs=100,\n",
        "batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.5963 - acc: 0.7922 - val_loss: 0.5044 - val_acc: 0.8239\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4870 - acc: 0.8314 - val_loss: 0.4784 - val_acc: 0.8343\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4678 - acc: 0.8364 - val_loss: 0.4771 - val_acc: 0.8339\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4562 - acc: 0.8411 - val_loss: 0.4725 - val_acc: 0.8362\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4475 - acc: 0.8460 - val_loss: 0.4637 - val_acc: 0.8403\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4438 - acc: 0.8463 - val_loss: 0.4577 - val_acc: 0.8414\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4383 - acc: 0.8474 - val_loss: 0.4566 - val_acc: 0.8425\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.4360 - acc: 0.8467 - val_loss: 0.4610 - val_acc: 0.8407\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4324 - acc: 0.8496 - val_loss: 0.4550 - val_acc: 0.8445\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4302 - acc: 0.8506 - val_loss: 0.4607 - val_acc: 0.8413\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4273 - acc: 0.8508 - val_loss: 0.4597 - val_acc: 0.8406\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4260 - acc: 0.8524 - val_loss: 0.4585 - val_acc: 0.8406\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4238 - acc: 0.8522 - val_loss: 0.4574 - val_acc: 0.8410\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4234 - acc: 0.8531 - val_loss: 0.4564 - val_acc: 0.8417\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4196 - acc: 0.8552 - val_loss: 0.4577 - val_acc: 0.8432\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4180 - acc: 0.8536 - val_loss: 0.4570 - val_acc: 0.8410\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4162 - acc: 0.8544 - val_loss: 0.4540 - val_acc: 0.8437\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4187 - acc: 0.8539 - val_loss: 0.4536 - val_acc: 0.8455\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4150 - acc: 0.8564 - val_loss: 0.4575 - val_acc: 0.8418\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4174 - acc: 0.8544 - val_loss: 0.4645 - val_acc: 0.8407\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4154 - acc: 0.8550 - val_loss: 0.4535 - val_acc: 0.8438\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4166 - acc: 0.8541 - val_loss: 0.4540 - val_acc: 0.8408\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4140 - acc: 0.8546 - val_loss: 0.4556 - val_acc: 0.8452\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4128 - acc: 0.8552 - val_loss: 0.4518 - val_acc: 0.8422\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4102 - acc: 0.8559 - val_loss: 0.4626 - val_acc: 0.8414\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4120 - acc: 0.8561 - val_loss: 0.4570 - val_acc: 0.8412\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4122 - acc: 0.8557 - val_loss: 0.4577 - val_acc: 0.8412\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4082 - acc: 0.8554 - val_loss: 0.4604 - val_acc: 0.8421\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4085 - acc: 0.8576 - val_loss: 0.4602 - val_acc: 0.8406\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4072 - acc: 0.8566 - val_loss: 0.4600 - val_acc: 0.8410\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4090 - acc: 0.8558 - val_loss: 0.4559 - val_acc: 0.8428\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4090 - acc: 0.8559 - val_loss: 0.4574 - val_acc: 0.8444\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4061 - acc: 0.8558 - val_loss: 0.4576 - val_acc: 0.8394\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4091 - acc: 0.8560 - val_loss: 0.4627 - val_acc: 0.8420\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4073 - acc: 0.8567 - val_loss: 0.4591 - val_acc: 0.8385\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4067 - acc: 0.8563 - val_loss: 0.4592 - val_acc: 0.8413\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4086 - acc: 0.8565 - val_loss: 0.4635 - val_acc: 0.8402\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.4073 - acc: 0.8570 - val_loss: 0.4568 - val_acc: 0.8395\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4077 - acc: 0.8554 - val_loss: 0.4572 - val_acc: 0.8432\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4070 - acc: 0.8564 - val_loss: 0.4618 - val_acc: 0.8402\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4055 - acc: 0.8574 - val_loss: 0.4560 - val_acc: 0.8439\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4027 - acc: 0.8573 - val_loss: 0.4582 - val_acc: 0.8434\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4065 - acc: 0.8564 - val_loss: 0.4628 - val_acc: 0.8431\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4035 - acc: 0.8587 - val_loss: 0.4603 - val_acc: 0.8412\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4047 - acc: 0.8571 - val_loss: 0.4582 - val_acc: 0.8402\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4037 - acc: 0.8573 - val_loss: 0.4602 - val_acc: 0.8412\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4048 - acc: 0.8565 - val_loss: 0.4557 - val_acc: 0.8445\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4025 - acc: 0.8574 - val_loss: 0.4614 - val_acc: 0.8417\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4042 - acc: 0.8569 - val_loss: 0.4597 - val_acc: 0.8418\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4015 - acc: 0.8586 - val_loss: 0.4573 - val_acc: 0.8410\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4032 - acc: 0.8582 - val_loss: 0.4645 - val_acc: 0.8396\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4026 - acc: 0.8576 - val_loss: 0.4616 - val_acc: 0.8400\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4010 - acc: 0.8588 - val_loss: 0.4595 - val_acc: 0.8420\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4017 - acc: 0.8574 - val_loss: 0.4610 - val_acc: 0.8408\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4016 - acc: 0.8590 - val_loss: 0.4618 - val_acc: 0.8405\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4032 - acc: 0.8575 - val_loss: 0.4630 - val_acc: 0.8407\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4015 - acc: 0.8585 - val_loss: 0.4603 - val_acc: 0.8433\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3993 - acc: 0.8598 - val_loss: 0.4633 - val_acc: 0.8411\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4008 - acc: 0.8583 - val_loss: 0.4625 - val_acc: 0.8397\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4014 - acc: 0.8578 - val_loss: 0.4616 - val_acc: 0.8454\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4005 - acc: 0.8587 - val_loss: 0.4629 - val_acc: 0.8423\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4004 - acc: 0.8586 - val_loss: 0.4581 - val_acc: 0.8438\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 0.4022 - acc: 0.8576 - val_loss: 0.4607 - val_acc: 0.8441\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4006 - acc: 0.8589 - val_loss: 0.4672 - val_acc: 0.8387\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3996 - acc: 0.8594 - val_loss: 0.4617 - val_acc: 0.8398\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3991 - acc: 0.8588 - val_loss: 0.4615 - val_acc: 0.8410\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.4002 - acc: 0.8587 - val_loss: 0.4615 - val_acc: 0.8391\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.3978 - acc: 0.8606 - val_loss: 0.4600 - val_acc: 0.8424\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3988 - acc: 0.8598 - val_loss: 0.4621 - val_acc: 0.8406\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3989 - acc: 0.8586 - val_loss: 0.4656 - val_acc: 0.8393\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3983 - acc: 0.8587 - val_loss: 0.4620 - val_acc: 0.8411\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4013 - acc: 0.8581 - val_loss: 0.4616 - val_acc: 0.8432\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3999 - acc: 0.8573 - val_loss: 0.4637 - val_acc: 0.8413\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3980 - acc: 0.8585 - val_loss: 0.4626 - val_acc: 0.8402\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3988 - acc: 0.8592 - val_loss: 0.4637 - val_acc: 0.8414\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.4004 - acc: 0.8577 - val_loss: 0.4674 - val_acc: 0.8391\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.4004 - acc: 0.8590 - val_loss: 0.4634 - val_acc: 0.8421\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3997 - acc: 0.8581 - val_loss: 0.4656 - val_acc: 0.8405\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3988 - acc: 0.8606 - val_loss: 0.4676 - val_acc: 0.8375\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3968 - acc: 0.8600 - val_loss: 0.4623 - val_acc: 0.8438\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.3966 - acc: 0.8597 - val_loss: 0.4667 - val_acc: 0.8400\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3965 - acc: 0.8607 - val_loss: 0.4661 - val_acc: 0.8391\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3951 - acc: 0.8602 - val_loss: 0.4606 - val_acc: 0.8422\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3970 - acc: 0.8604 - val_loss: 0.4673 - val_acc: 0.8398\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3970 - acc: 0.8594 - val_loss: 0.4648 - val_acc: 0.8441\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3965 - acc: 0.8600 - val_loss: 0.4650 - val_acc: 0.8402\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3978 - acc: 0.8586 - val_loss: 0.4636 - val_acc: 0.8404\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3970 - acc: 0.8592 - val_loss: 0.4651 - val_acc: 0.8425\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3975 - acc: 0.8594 - val_loss: 0.4651 - val_acc: 0.8405\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3962 - acc: 0.8582 - val_loss: 0.4771 - val_acc: 0.8383\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 3s 57us/sample - loss: 0.3975 - acc: 0.8595 - val_loss: 0.4645 - val_acc: 0.8430\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3975 - acc: 0.8592 - val_loss: 0.4652 - val_acc: 0.8414\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3963 - acc: 0.8599 - val_loss: 0.4736 - val_acc: 0.8350\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3949 - acc: 0.8586 - val_loss: 0.4689 - val_acc: 0.8399\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3960 - acc: 0.8605 - val_loss: 0.4663 - val_acc: 0.8407\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3984 - acc: 0.8581 - val_loss: 0.4645 - val_acc: 0.8407\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3980 - acc: 0.8593 - val_loss: 0.4629 - val_acc: 0.8437\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3948 - acc: 0.8601 - val_loss: 0.4657 - val_acc: 0.8450\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3983 - acc: 0.8582 - val_loss: 0.4672 - val_acc: 0.8392\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3961 - acc: 0.8599 - val_loss: 0.4634 - val_acc: 0.8405\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efdaf295ed0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Py-KwkmjOIVU",
        "colab_type": "text"
      },
      "source": [
        "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLXUE9jWOIVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.001)\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy',\n",
        "metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pJUqA5T4OIVc",
        "colab_type": "code",
        "outputId": "ceb7d01f-6db0-42cb-ba31-96ca6d53808a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3410
        }
      },
      "source": [
        "model.fit(trainX,trainY,\n",
        "validation_data=(testX,testY),\n",
        "epochs=100,\n",
        "batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3975 - acc: 0.8594 - val_loss: 0.4664 - val_acc: 0.8434\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3953 - acc: 0.8590 - val_loss: 0.4693 - val_acc: 0.8385\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3957 - acc: 0.8595 - val_loss: 0.4649 - val_acc: 0.8429\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3949 - acc: 0.8611 - val_loss: 0.4728 - val_acc: 0.8402\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.3962 - acc: 0.8596 - val_loss: 0.4688 - val_acc: 0.8391\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.3976 - acc: 0.8594 - val_loss: 0.4691 - val_acc: 0.8406\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3960 - acc: 0.8595 - val_loss: 0.4675 - val_acc: 0.8407\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3965 - acc: 0.8596 - val_loss: 0.4683 - val_acc: 0.8437\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3955 - acc: 0.8597 - val_loss: 0.4656 - val_acc: 0.8413\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.3961 - acc: 0.8586 - val_loss: 0.4662 - val_acc: 0.8423\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3959 - acc: 0.8580 - val_loss: 0.4660 - val_acc: 0.8420\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3957 - acc: 0.8592 - val_loss: 0.4698 - val_acc: 0.8422\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3947 - acc: 0.8598 - val_loss: 0.4725 - val_acc: 0.8382\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3950 - acc: 0.8594 - val_loss: 0.4689 - val_acc: 0.8385\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3942 - acc: 0.8603 - val_loss: 0.4666 - val_acc: 0.8410\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3947 - acc: 0.8582 - val_loss: 0.4649 - val_acc: 0.8419\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3944 - acc: 0.8591 - val_loss: 0.4679 - val_acc: 0.8386\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3957 - acc: 0.8599 - val_loss: 0.4706 - val_acc: 0.8416\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3950 - acc: 0.8591 - val_loss: 0.4723 - val_acc: 0.8378\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3937 - acc: 0.8602 - val_loss: 0.4708 - val_acc: 0.8400\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3956 - acc: 0.8608 - val_loss: 0.4724 - val_acc: 0.8401\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3952 - acc: 0.8598 - val_loss: 0.4637 - val_acc: 0.8432\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 4s 62us/sample - loss: 0.3984 - acc: 0.8590 - val_loss: 0.4665 - val_acc: 0.8410\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3952 - acc: 0.8590 - val_loss: 0.4712 - val_acc: 0.8425\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3936 - acc: 0.8599 - val_loss: 0.4725 - val_acc: 0.8388\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3941 - acc: 0.8593 - val_loss: 0.4754 - val_acc: 0.8391\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3955 - acc: 0.8587 - val_loss: 0.4663 - val_acc: 0.8441\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3947 - acc: 0.8596 - val_loss: 0.4646 - val_acc: 0.8429\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3926 - acc: 0.8605 - val_loss: 0.4670 - val_acc: 0.8422\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3929 - acc: 0.8595 - val_loss: 0.4688 - val_acc: 0.8422\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3938 - acc: 0.8607 - val_loss: 0.4701 - val_acc: 0.8433\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3934 - acc: 0.8590 - val_loss: 0.4698 - val_acc: 0.8418\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3929 - acc: 0.8602 - val_loss: 0.4720 - val_acc: 0.8386\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3928 - acc: 0.8600 - val_loss: 0.4751 - val_acc: 0.8410\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3930 - acc: 0.8613 - val_loss: 0.4691 - val_acc: 0.8417\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3945 - acc: 0.8605 - val_loss: 0.4727 - val_acc: 0.8377\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3955 - acc: 0.8587 - val_loss: 0.4663 - val_acc: 0.8412\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3940 - acc: 0.8601 - val_loss: 0.4698 - val_acc: 0.8421\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3943 - acc: 0.8595 - val_loss: 0.4737 - val_acc: 0.8411\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3948 - acc: 0.8597 - val_loss: 0.4726 - val_acc: 0.8387\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3943 - acc: 0.8604 - val_loss: 0.4705 - val_acc: 0.8381\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3947 - acc: 0.8602 - val_loss: 0.4723 - val_acc: 0.8408\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.3924 - acc: 0.8602 - val_loss: 0.4823 - val_acc: 0.8353\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3949 - acc: 0.8597 - val_loss: 0.4760 - val_acc: 0.8388\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3924 - acc: 0.8608 - val_loss: 0.4737 - val_acc: 0.8392\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3948 - acc: 0.8600 - val_loss: 0.4689 - val_acc: 0.8435\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3948 - acc: 0.8598 - val_loss: 0.4729 - val_acc: 0.8375\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3934 - acc: 0.8600 - val_loss: 0.4681 - val_acc: 0.8398\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3935 - acc: 0.8601 - val_loss: 0.4674 - val_acc: 0.8396\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3929 - acc: 0.8597 - val_loss: 0.4750 - val_acc: 0.8411\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3929 - acc: 0.8599 - val_loss: 0.4752 - val_acc: 0.8393\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3934 - acc: 0.8600 - val_loss: 0.4710 - val_acc: 0.8393\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3936 - acc: 0.8590 - val_loss: 0.4746 - val_acc: 0.8374\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3938 - acc: 0.8611 - val_loss: 0.4765 - val_acc: 0.8363\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3912 - acc: 0.8613 - val_loss: 0.4738 - val_acc: 0.8417\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3950 - acc: 0.8609 - val_loss: 0.4747 - val_acc: 0.8374\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.3937 - acc: 0.8589 - val_loss: 0.4732 - val_acc: 0.8374\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.3936 - acc: 0.8600 - val_loss: 0.4721 - val_acc: 0.8381\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3930 - acc: 0.8608 - val_loss: 0.4741 - val_acc: 0.8364\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3928 - acc: 0.8606 - val_loss: 0.4728 - val_acc: 0.8389\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3926 - acc: 0.8593 - val_loss: 0.4720 - val_acc: 0.8406\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3953 - acc: 0.8602 - val_loss: 0.4745 - val_acc: 0.8394\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 4s 61us/sample - loss: 0.3945 - acc: 0.8592 - val_loss: 0.4746 - val_acc: 0.8399\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3916 - acc: 0.8601 - val_loss: 0.4750 - val_acc: 0.8395\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3936 - acc: 0.8602 - val_loss: 0.4732 - val_acc: 0.8392\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3913 - acc: 0.8605 - val_loss: 0.4720 - val_acc: 0.8417\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.3919 - acc: 0.8601 - val_loss: 0.4697 - val_acc: 0.8413\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3920 - acc: 0.8600 - val_loss: 0.4752 - val_acc: 0.8419\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3918 - acc: 0.8609 - val_loss: 0.4759 - val_acc: 0.8386\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3903 - acc: 0.8626 - val_loss: 0.4722 - val_acc: 0.8396\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3949 - acc: 0.8593 - val_loss: 0.4718 - val_acc: 0.8423\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3904 - acc: 0.8607 - val_loss: 0.4738 - val_acc: 0.8361\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3904 - acc: 0.8602 - val_loss: 0.4745 - val_acc: 0.8391\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3920 - acc: 0.8610 - val_loss: 0.4765 - val_acc: 0.8390\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3922 - acc: 0.8604 - val_loss: 0.4709 - val_acc: 0.8407\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.3947 - acc: 0.8589 - val_loss: 0.4746 - val_acc: 0.8381\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3932 - acc: 0.8600 - val_loss: 0.4720 - val_acc: 0.8389\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3931 - acc: 0.8603 - val_loss: 0.4729 - val_acc: 0.8413\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3925 - acc: 0.8601 - val_loss: 0.4710 - val_acc: 0.8403\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3940 - acc: 0.8588 - val_loss: 0.4743 - val_acc: 0.8392\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3919 - acc: 0.8596 - val_loss: 0.4692 - val_acc: 0.8413\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 4s 60us/sample - loss: 0.3912 - acc: 0.8610 - val_loss: 0.4733 - val_acc: 0.8396\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 4s 63us/sample - loss: 0.3932 - acc: 0.8599 - val_loss: 0.4836 - val_acc: 0.8362\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3901 - acc: 0.8622 - val_loss: 0.4722 - val_acc: 0.8404\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3910 - acc: 0.8608 - val_loss: 0.4702 - val_acc: 0.8420\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 4s 58us/sample - loss: 0.3922 - acc: 0.8595 - val_loss: 0.4704 - val_acc: 0.8403\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3919 - acc: 0.8618 - val_loss: 0.4721 - val_acc: 0.8402\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3937 - acc: 0.8592 - val_loss: 0.4735 - val_acc: 0.8376\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3949 - acc: 0.8591 - val_loss: 0.4727 - val_acc: 0.8411\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3921 - acc: 0.8604 - val_loss: 0.4738 - val_acc: 0.8390\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3910 - acc: 0.8609 - val_loss: 0.4738 - val_acc: 0.8419\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3941 - acc: 0.8595 - val_loss: 0.4752 - val_acc: 0.8364\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3929 - acc: 0.8593 - val_loss: 0.4756 - val_acc: 0.8407\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3917 - acc: 0.8603 - val_loss: 0.4713 - val_acc: 0.8414\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3922 - acc: 0.8612 - val_loss: 0.4736 - val_acc: 0.8396\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3914 - acc: 0.8608 - val_loss: 0.4749 - val_acc: 0.8390\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3924 - acc: 0.8601 - val_loss: 0.4758 - val_acc: 0.8392\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3910 - acc: 0.8609 - val_loss: 0.4750 - val_acc: 0.8385\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 4s 59us/sample - loss: 0.3911 - acc: 0.8609 - val_loss: 0.4718 - val_acc: 0.8429\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 3s 58us/sample - loss: 0.3922 - acc: 0.8594 - val_loss: 0.4723 - val_acc: 0.8406\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efdac8e0810>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CSqKvpOIVk",
        "colab_type": "text"
      },
      "source": [
        "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCr-E_Slho9Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Reshape((784,),input_shape=(28,28,)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "\n",
        "model.add(tf.keras.layers.Dense(100, activation ='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(100, activation ='sigmoid'))\n",
        "model.add(tf.keras.layers.Dense(10, activation='softmax'))\n",
        "sgd_optimizer = tf.keras.optimizers.SGD(lr=0.03)\n",
        "model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktByAjkjkmbM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nr2YsZV0OIV0",
        "colab_type": "text"
      },
      "source": [
        "## Review model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4ojW6-oOIV2",
        "colab_type": "code",
        "outputId": "a52a465a-6893-4a7b-d9c8-de2ff4a2879d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "reshape_11 (Reshape)         (None, 784)               0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 784)               3136      \n",
            "_________________________________________________________________\n",
            "dense_23 (Dense)             (None, 100)               78500     \n",
            "_________________________________________________________________\n",
            "dense_24 (Dense)             (None, 100)               10100     \n",
            "_________________________________________________________________\n",
            "dense_25 (Dense)             (None, 10)                1010      \n",
            "=================================================================\n",
            "Total params: 92,746\n",
            "Trainable params: 91,178\n",
            "Non-trainable params: 1,568\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfFGmbZLOIV5",
        "colab_type": "text"
      },
      "source": [
        "### Run the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bIkbMEN5OIV7",
        "colab_type": "code",
        "outputId": "a197a915-cdf5-4f97-8afd-fecf36a80ddb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3410
        }
      },
      "source": [
        "model.fit(trainX,trainY,\n",
        "validation_data=(testX,testY),\n",
        "epochs=100,\n",
        "batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.9052 - acc: 0.7269 - val_loss: 0.7541 - val_acc: 0.7492\n",
            "Epoch 2/100\n",
            "60000/60000 [==============================] - 5s 89us/sample - loss: 0.7046 - acc: 0.7564 - val_loss: 0.6422 - val_acc: 0.7703\n",
            "Epoch 3/100\n",
            "60000/60000 [==============================] - 5s 89us/sample - loss: 0.6206 - acc: 0.7800 - val_loss: 0.5826 - val_acc: 0.7905\n",
            "Epoch 4/100\n",
            "60000/60000 [==============================] - 5s 89us/sample - loss: 0.5705 - acc: 0.7982 - val_loss: 0.5431 - val_acc: 0.8069\n",
            "Epoch 5/100\n",
            "60000/60000 [==============================] - 5s 89us/sample - loss: 0.5334 - acc: 0.8123 - val_loss: 0.5142 - val_acc: 0.8164\n",
            "Epoch 6/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.5072 - acc: 0.8193 - val_loss: 0.4941 - val_acc: 0.8245\n",
            "Epoch 7/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.4859 - acc: 0.8281 - val_loss: 0.4784 - val_acc: 0.8299\n",
            "Epoch 8/100\n",
            "60000/60000 [==============================] - 5s 88us/sample - loss: 0.4714 - acc: 0.8317 - val_loss: 0.4667 - val_acc: 0.8305\n",
            "Epoch 9/100\n",
            "60000/60000 [==============================] - 5s 89us/sample - loss: 0.4587 - acc: 0.8359 - val_loss: 0.4582 - val_acc: 0.8341\n",
            "Epoch 10/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.4499 - acc: 0.8397 - val_loss: 0.4495 - val_acc: 0.8384\n",
            "Epoch 11/100\n",
            "60000/60000 [==============================] - 5s 89us/sample - loss: 0.4403 - acc: 0.8439 - val_loss: 0.4434 - val_acc: 0.8410\n",
            "Epoch 12/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.4334 - acc: 0.8458 - val_loss: 0.4356 - val_acc: 0.8413\n",
            "Epoch 13/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.4264 - acc: 0.8478 - val_loss: 0.4306 - val_acc: 0.8445\n",
            "Epoch 14/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.4183 - acc: 0.8506 - val_loss: 0.4263 - val_acc: 0.8457\n",
            "Epoch 15/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.4138 - acc: 0.8531 - val_loss: 0.4211 - val_acc: 0.8494\n",
            "Epoch 16/100\n",
            "60000/60000 [==============================] - 5s 89us/sample - loss: 0.4091 - acc: 0.8546 - val_loss: 0.4167 - val_acc: 0.8499\n",
            "Epoch 17/100\n",
            "60000/60000 [==============================] - 5s 89us/sample - loss: 0.4031 - acc: 0.8569 - val_loss: 0.4134 - val_acc: 0.8516\n",
            "Epoch 18/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.3986 - acc: 0.8594 - val_loss: 0.4090 - val_acc: 0.8524\n",
            "Epoch 19/100\n",
            "60000/60000 [==============================] - 5s 89us/sample - loss: 0.3927 - acc: 0.8602 - val_loss: 0.4052 - val_acc: 0.8551\n",
            "Epoch 20/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3894 - acc: 0.8616 - val_loss: 0.4015 - val_acc: 0.8555\n",
            "Epoch 21/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.3852 - acc: 0.8630 - val_loss: 0.4002 - val_acc: 0.8567\n",
            "Epoch 22/100\n",
            "60000/60000 [==============================] - 5s 92us/sample - loss: 0.3829 - acc: 0.8642 - val_loss: 0.3961 - val_acc: 0.8587\n",
            "Epoch 23/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3800 - acc: 0.8652 - val_loss: 0.3947 - val_acc: 0.8587\n",
            "Epoch 24/100\n",
            "60000/60000 [==============================] - 6s 96us/sample - loss: 0.3745 - acc: 0.8672 - val_loss: 0.3915 - val_acc: 0.8585\n",
            "Epoch 25/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.3708 - acc: 0.8680 - val_loss: 0.3878 - val_acc: 0.8603\n",
            "Epoch 26/100\n",
            "60000/60000 [==============================] - 5s 89us/sample - loss: 0.3653 - acc: 0.8688 - val_loss: 0.3867 - val_acc: 0.8610\n",
            "Epoch 27/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.3649 - acc: 0.8701 - val_loss: 0.3834 - val_acc: 0.8627\n",
            "Epoch 28/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3621 - acc: 0.8716 - val_loss: 0.3808 - val_acc: 0.8644\n",
            "Epoch 29/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3580 - acc: 0.8726 - val_loss: 0.3786 - val_acc: 0.8628\n",
            "Epoch 30/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3558 - acc: 0.8721 - val_loss: 0.3772 - val_acc: 0.8646\n",
            "Epoch 31/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.3527 - acc: 0.8742 - val_loss: 0.3739 - val_acc: 0.8655\n",
            "Epoch 32/100\n",
            "60000/60000 [==============================] - 5s 90us/sample - loss: 0.3490 - acc: 0.8761 - val_loss: 0.3740 - val_acc: 0.8663\n",
            "Epoch 33/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3461 - acc: 0.8758 - val_loss: 0.3706 - val_acc: 0.8676\n",
            "Epoch 34/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3430 - acc: 0.8785 - val_loss: 0.3681 - val_acc: 0.8678\n",
            "Epoch 35/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.3432 - acc: 0.8778 - val_loss: 0.3673 - val_acc: 0.8673\n",
            "Epoch 36/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.3390 - acc: 0.8780 - val_loss: 0.3656 - val_acc: 0.8697\n",
            "Epoch 37/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.3359 - acc: 0.8802 - val_loss: 0.3643 - val_acc: 0.8700\n",
            "Epoch 38/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3329 - acc: 0.8805 - val_loss: 0.3612 - val_acc: 0.8700\n",
            "Epoch 39/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3292 - acc: 0.8828 - val_loss: 0.3603 - val_acc: 0.8712\n",
            "Epoch 40/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3282 - acc: 0.8825 - val_loss: 0.3597 - val_acc: 0.8702\n",
            "Epoch 41/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3254 - acc: 0.8837 - val_loss: 0.3591 - val_acc: 0.8699\n",
            "Epoch 42/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3242 - acc: 0.8833 - val_loss: 0.3555 - val_acc: 0.8725\n",
            "Epoch 43/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.3220 - acc: 0.8852 - val_loss: 0.3555 - val_acc: 0.8718\n",
            "Epoch 44/100\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.3203 - acc: 0.8853 - val_loss: 0.3540 - val_acc: 0.8726\n",
            "Epoch 45/100\n",
            "60000/60000 [==============================] - 6s 94us/sample - loss: 0.3172 - acc: 0.8877 - val_loss: 0.3516 - val_acc: 0.8723\n",
            "Epoch 46/100\n",
            "60000/60000 [==============================] - 6s 96us/sample - loss: 0.3131 - acc: 0.8877 - val_loss: 0.3504 - val_acc: 0.8735\n",
            "Epoch 47/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.3125 - acc: 0.8885 - val_loss: 0.3495 - val_acc: 0.8744\n",
            "Epoch 48/100\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.3122 - acc: 0.8877 - val_loss: 0.3489 - val_acc: 0.8739\n",
            "Epoch 49/100\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.3096 - acc: 0.8901 - val_loss: 0.3501 - val_acc: 0.8745\n",
            "Epoch 50/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.3055 - acc: 0.8907 - val_loss: 0.3468 - val_acc: 0.8768\n",
            "Epoch 51/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.3047 - acc: 0.8900 - val_loss: 0.3467 - val_acc: 0.8747\n",
            "Epoch 52/100\n",
            "60000/60000 [==============================] - 6s 94us/sample - loss: 0.3010 - acc: 0.8922 - val_loss: 0.3451 - val_acc: 0.8741\n",
            "Epoch 53/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.3012 - acc: 0.8921 - val_loss: 0.3428 - val_acc: 0.8767\n",
            "Epoch 54/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2983 - acc: 0.8935 - val_loss: 0.3429 - val_acc: 0.8769\n",
            "Epoch 55/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2963 - acc: 0.8946 - val_loss: 0.3428 - val_acc: 0.8772\n",
            "Epoch 56/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2942 - acc: 0.8950 - val_loss: 0.3399 - val_acc: 0.8762\n",
            "Epoch 57/100\n",
            "60000/60000 [==============================] - 6s 96us/sample - loss: 0.2917 - acc: 0.8964 - val_loss: 0.3402 - val_acc: 0.8749\n",
            "Epoch 58/100\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2908 - acc: 0.8957 - val_loss: 0.3408 - val_acc: 0.8782\n",
            "Epoch 59/100\n",
            "60000/60000 [==============================] - 6s 94us/sample - loss: 0.2888 - acc: 0.8977 - val_loss: 0.3402 - val_acc: 0.8756\n",
            "Epoch 60/100\n",
            "60000/60000 [==============================] - 6s 94us/sample - loss: 0.2875 - acc: 0.8983 - val_loss: 0.3373 - val_acc: 0.8789\n",
            "Epoch 61/100\n",
            "60000/60000 [==============================] - 6s 94us/sample - loss: 0.2844 - acc: 0.8984 - val_loss: 0.3393 - val_acc: 0.8761\n",
            "Epoch 62/100\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2820 - acc: 0.9000 - val_loss: 0.3371 - val_acc: 0.8775\n",
            "Epoch 63/100\n",
            "60000/60000 [==============================] - 6s 103us/sample - loss: 0.2794 - acc: 0.8995 - val_loss: 0.3360 - val_acc: 0.8772\n",
            "Epoch 64/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.2788 - acc: 0.8999 - val_loss: 0.3358 - val_acc: 0.8793\n",
            "Epoch 65/100\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2773 - acc: 0.9007 - val_loss: 0.3359 - val_acc: 0.8805\n",
            "Epoch 66/100\n",
            "60000/60000 [==============================] - 6s 94us/sample - loss: 0.2737 - acc: 0.9025 - val_loss: 0.3336 - val_acc: 0.8795\n",
            "Epoch 67/100\n",
            "60000/60000 [==============================] - 6s 94us/sample - loss: 0.2742 - acc: 0.9021 - val_loss: 0.3350 - val_acc: 0.8768\n",
            "Epoch 68/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2726 - acc: 0.9027 - val_loss: 0.3314 - val_acc: 0.8791\n",
            "Epoch 69/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2704 - acc: 0.9036 - val_loss: 0.3316 - val_acc: 0.8798\n",
            "Epoch 70/100\n",
            "60000/60000 [==============================] - 6s 94us/sample - loss: 0.2701 - acc: 0.9029 - val_loss: 0.3308 - val_acc: 0.8813\n",
            "Epoch 71/100\n",
            "60000/60000 [==============================] - 6s 94us/sample - loss: 0.2677 - acc: 0.9047 - val_loss: 0.3328 - val_acc: 0.8796\n",
            "Epoch 72/100\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2646 - acc: 0.9053 - val_loss: 0.3339 - val_acc: 0.8809\n",
            "Epoch 73/100\n",
            "60000/60000 [==============================] - 6s 96us/sample - loss: 0.2624 - acc: 0.9062 - val_loss: 0.3316 - val_acc: 0.8815\n",
            "Epoch 74/100\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2617 - acc: 0.9064 - val_loss: 0.3289 - val_acc: 0.8820\n",
            "Epoch 75/100\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2619 - acc: 0.9057 - val_loss: 0.3295 - val_acc: 0.8808\n",
            "Epoch 76/100\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2585 - acc: 0.9084 - val_loss: 0.3305 - val_acc: 0.8811\n",
            "Epoch 77/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2566 - acc: 0.9079 - val_loss: 0.3287 - val_acc: 0.8799\n",
            "Epoch 78/100\n",
            "60000/60000 [==============================] - 6s 97us/sample - loss: 0.2553 - acc: 0.9075 - val_loss: 0.3287 - val_acc: 0.8829\n",
            "Epoch 79/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.2541 - acc: 0.9082 - val_loss: 0.3297 - val_acc: 0.8816\n",
            "Epoch 80/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2511 - acc: 0.9096 - val_loss: 0.3317 - val_acc: 0.8809\n",
            "Epoch 81/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2518 - acc: 0.9094 - val_loss: 0.3279 - val_acc: 0.8833\n",
            "Epoch 82/100\n",
            "60000/60000 [==============================] - 5s 92us/sample - loss: 0.2498 - acc: 0.9107 - val_loss: 0.3281 - val_acc: 0.8827\n",
            "Epoch 83/100\n",
            "60000/60000 [==============================] - 6s 94us/sample - loss: 0.2465 - acc: 0.9113 - val_loss: 0.3275 - val_acc: 0.8821\n",
            "Epoch 84/100\n",
            "60000/60000 [==============================] - 6s 101us/sample - loss: 0.2466 - acc: 0.9115 - val_loss: 0.3271 - val_acc: 0.8833\n",
            "Epoch 85/100\n",
            "60000/60000 [==============================] - 6s 100us/sample - loss: 0.2452 - acc: 0.9117 - val_loss: 0.3298 - val_acc: 0.8814\n",
            "Epoch 86/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.2423 - acc: 0.9136 - val_loss: 0.3265 - val_acc: 0.8817\n",
            "Epoch 87/100\n",
            "60000/60000 [==============================] - 6s 99us/sample - loss: 0.2415 - acc: 0.9132 - val_loss: 0.3267 - val_acc: 0.8823\n",
            "Epoch 88/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2418 - acc: 0.9131 - val_loss: 0.3265 - val_acc: 0.8847\n",
            "Epoch 89/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2378 - acc: 0.9147 - val_loss: 0.3249 - val_acc: 0.8825\n",
            "Epoch 90/100\n",
            "60000/60000 [==============================] - 6s 93us/sample - loss: 0.2368 - acc: 0.9158 - val_loss: 0.3259 - val_acc: 0.8823\n",
            "Epoch 91/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2352 - acc: 0.9162 - val_loss: 0.3312 - val_acc: 0.8813\n",
            "Epoch 92/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2341 - acc: 0.9158 - val_loss: 0.3272 - val_acc: 0.8846\n",
            "Epoch 93/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2296 - acc: 0.9181 - val_loss: 0.3291 - val_acc: 0.8839\n",
            "Epoch 94/100\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2315 - acc: 0.9169 - val_loss: 0.3267 - val_acc: 0.8849\n",
            "Epoch 95/100\n",
            "60000/60000 [==============================] - 6s 98us/sample - loss: 0.2289 - acc: 0.9182 - val_loss: 0.3257 - val_acc: 0.8840\n",
            "Epoch 96/100\n",
            "60000/60000 [==============================] - 6s 95us/sample - loss: 0.2292 - acc: 0.9178 - val_loss: 0.3263 - val_acc: 0.8835\n",
            "Epoch 97/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2270 - acc: 0.9190 - val_loss: 0.3272 - val_acc: 0.8849\n",
            "Epoch 98/100\n",
            "60000/60000 [==============================] - 5s 91us/sample - loss: 0.2256 - acc: 0.9195 - val_loss: 0.3245 - val_acc: 0.8845\n",
            "Epoch 99/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2233 - acc: 0.9208 - val_loss: 0.3261 - val_acc: 0.8848\n",
            "Epoch 100/100\n",
            "60000/60000 [==============================] - 6s 92us/sample - loss: 0.2237 - acc: 0.9201 - val_loss: 0.3265 - val_acc: 0.8846\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7efda56d3a50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7kB8duR-pHen",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}